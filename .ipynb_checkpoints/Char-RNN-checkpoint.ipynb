{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6277c58e",
   "metadata": {},
   "source": [
    "# MUSIC GENERATION USING RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52828a6e",
   "metadata": {},
   "source": [
    "#### Initialization of helper functions and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6a0760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start with some packages we need\n",
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a2a47f",
   "metadata": {},
   "source": [
    "#### Sentence Tokenization and indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6419fdbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping unique tokens to integers: {']': 0, '[': 1, ' ': 2, 'M': 3, 'N': 4, 'o': 5, 'K': 6, '&': 7, 'E': 8, '?': 9, '>': 10, '8': 11, 'J': 12, 'Q': 13, '\"': 14, '.': 15, 'I': 16, '0': 17, 'O': 18, '%': 19, 'a': 20, 'm': 21, 'd': 22, ')': 23, '4': 24, '/': 25, 'e': 26, 'S': 27, '<': 28, '2': 29, 'F': 30, 'r': 31, 'q': 32, 'z': 33, 'R': 34, 'A': 35, '1': 36, '(': 37, 'l': 38, 'h': 39, '~': 40, 'n': 41, 'k': 42, 'i': 43, '#': 44, 'W': 45, 'j': 46, ':': 47, 'H': 48, '+': 49, '|': 50, 'c': 51, 'L': 52, 'u': 53, 'y': 54, 'b': 55, 'V': 56, 's': 57, 'B': 58, '-': 59, 'U': 60, 'T': 61, '!': 62, '\\n': 63, 'G': 64, '3': 65, '^': 66, 'X': 67, 'v': 68, 'p': 69, '\\\\': 70, 'x': 71, 'Y': 72, 'f': 73, '9': 74, '7': 75, 'g': 76, '_': 77, ',': 78, 'w': 79, 't': 80, \"'\": 81, '=': 82, '6': 83, 'C': 84, 'P': 85, '5': 86, 'D': 87} \n",
      "\n",
      "example sentence as string: <start>\n",
      "X: 1\n",
      "T:A and D\n",
      "% Nottingham Music Database\n",
      "S:EF\n",
      "Y:AB\n",
      "M:4/4\n",
      "K:A\n",
      "M:6/8\n",
      "P:A\n",
      "f|\"A\"ecc c2f|\"A\"ecc c2f|\"A\"ecc c2f|\"Bm\"BcB \"E7\"B2f|\n",
      "\"A\"ecc c2f|\"A\"ecc c2c/2d/2|\"D\"efe \"E7\"dcB| [1\"A\"Ace a2:|\n",
      " [2\"A\"Ace ag=g||\n",
      "K:D\n",
      "P:B\n",
      "\"D\"f2f Fdd|\"D\"AFA f2e/2f/2|\"G\"g2g ecd|\"Em\"efd \"A7\"cBA|\n",
      "\"D\"f^ef dcd|\"D\"AFA f=ef|\"G\"gfg \"A7\"ABc |[1\"D\"d3 d2e:|[2\"D\"d3 d2||\n",
      "<end>\n",
      " \n",
      "\n",
      "example sentence as tensor: tensor([28, 57, 80, 20, 31, 80, 10, 63, 67, 47,  2, 36, 63, 61, 47, 35,  2, 20,\n",
      "        41, 22,  2, 87, 63, 19,  2,  4,  5, 80, 80, 43, 41, 76, 39, 20, 21,  2,\n",
      "         3, 53, 57, 43, 51,  2, 87, 20, 80, 20, 55, 20, 57, 26, 63, 27, 47,  8,\n",
      "        30, 63, 72, 47, 35, 58, 63,  3, 47, 24, 25, 24, 63,  6, 47, 35, 63,  3,\n",
      "        47, 83, 25, 11, 63, 85, 47, 35, 63, 73, 50, 14, 35, 14, 26, 51, 51,  2,\n",
      "        51, 29, 73, 50, 14, 35, 14, 26, 51, 51,  2, 51, 29, 73, 50, 14, 35, 14,\n",
      "        26, 51, 51,  2, 51, 29, 73, 50, 14, 58, 21, 14, 58, 51, 58,  2, 14,  8,\n",
      "        75, 14, 58, 29, 73, 50, 63, 14, 35, 14, 26, 51, 51,  2, 51, 29, 73, 50,\n",
      "        14, 35, 14, 26, 51, 51,  2, 51, 29, 51, 25, 29, 22, 25, 29, 50, 14, 87,\n",
      "        14, 26, 73, 26,  2, 14,  8, 75, 14, 22, 51, 58, 50,  2,  1, 36, 14, 35,\n",
      "        14, 35, 51, 26,  2, 20, 29, 47, 50, 63,  2,  1, 29, 14, 35, 14, 35, 51,\n",
      "        26,  2, 20, 76, 82, 76, 50, 50, 63,  6, 47, 87, 63, 85, 47, 58, 63, 14,\n",
      "        87, 14, 73, 29, 73,  2, 30, 22, 22, 50, 14, 87, 14, 35, 30, 35,  2, 73,\n",
      "        29, 26, 25, 29, 73, 25, 29, 50, 14, 64, 14, 76, 29, 76,  2, 26, 51, 22,\n",
      "        50, 14,  8, 21, 14, 26, 73, 22,  2, 14, 35, 75, 14, 51, 58, 35, 50, 63,\n",
      "        14, 87, 14, 73, 66, 26, 73,  2, 22, 51, 22, 50, 14, 87, 14, 35, 30, 35,\n",
      "         2, 73, 82, 26, 73, 50, 14, 64, 14, 76, 73, 76,  2, 14, 35, 75, 14, 35,\n",
      "        58, 51,  2, 50,  1, 36, 14, 87, 14, 22, 65,  2, 22, 29, 26, 47, 50,  1,\n",
      "        29, 14, 87, 14, 22, 65,  2, 22, 29, 50, 50, 63, 28, 26, 41, 22, 10, 63]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def sentenceToTensor(tokens):\n",
    "    # Convert list of strings to tensor of token indices (integers)\n",
    "    #\n",
    "    # Input\n",
    "    #  tokens_list : list of strings, e.g. ['<SOS>','lion','eat','man','<EOS>']\n",
    "    # Output\n",
    "    #  1D tensor of the same length (integers), e.g., tensor([ 2, 18, 13, 19,  0])\n",
    "    out = torch.zeros(len(tokens)).long()\n",
    "    for i, token in enumerate(tokens):\n",
    "        out[i] = char_idx.index(token)\n",
    "    return out\n",
    "\n",
    "# load and process the set of simple sentences\n",
    "with open('data/input.txt','r') as fid:\n",
    "    lines = fid.readlines()\n",
    "\n",
    "cur_line = ''\n",
    "input_lines = []\n",
    "for line in lines:\n",
    "    if line == '\\n':\n",
    "        input_lines.append(cur_line)\n",
    "        cur_line = ''\n",
    "        continue\n",
    "    cur_line += line\n",
    "\n",
    "input_lines = [s for s in input_lines if len(s)>0]\n",
    "input_lines = ['<start>\\n'+s+'<end>\\n' for s in input_lines]\n",
    "\n",
    "char_idx = ''.join(set(list((open('data/input.txt','r').read()) + '<start>' + '<end>')))\n",
    "unique_tokens = list(char_idx)\n",
    "    \n",
    "n_tokens = len(unique_tokens) # all words and special tokens\n",
    "\n",
    "token_to_index = {t : i for i,t in enumerate(unique_tokens)}\n",
    "index_to_token = {i : t for i,t in enumerate(unique_tokens)}\n",
    "\n",
    "training_pats = [sentenceToTensor(s) for s in input_lines]\n",
    "training_pats = [s for s in training_pats if s.size()[0]>0]\n",
    "\n",
    "ntrain = len(training_pats)\n",
    "print('mapping unique tokens to integers: %s \\n' % token_to_index)\n",
    "print('example sentence as string: %s \\n' % ''.join(input_lines[0]))\n",
    "print('example sentence as tensor: %s \\n' % training_pats[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaad770c",
   "metadata": {},
   "source": [
    "### Music Recurrent Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31ce100",
   "metadata": {},
   "source": [
    "#### RNN Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0fe40b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicGRU(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        self.word_embeddings = nn.Embedding(input_size, hidden_size)\n",
    "        self.rnn = nn.GRU(hidden_size, hidden_size, num_layers)\n",
    "        self.fc1 = nn.Linear(self.hidden_size, self.output_size)\n",
    "        \n",
    "    def forward(self, input_token):\n",
    "        input_embed = self.word_embeddings(input_token)\n",
    "        input_embed = input_embed.view(1, 1, -1)\n",
    "        rnn_out, self.hidden = self.rnn(input_embed, self.hidden)\n",
    "        output = self.fc1(rnn_out.view(1, -1))\n",
    "        return output\n",
    "\n",
    "    def initHidden(self):\n",
    "        # Returns length hidden_size 1D tensor of zeros\n",
    "        self.hidden = torch.zeros(self.num_layers, 1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9571eaa4",
   "metadata": {},
   "source": [
    "#### Training Loop and Loss Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a8b6b7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(seq_tensor, rnn):\n",
    "    target = seq_tensor\n",
    "    target = torch.cat([target[1:]])\n",
    "    outputs = []\n",
    "    rnn.initHidden()\n",
    "    optimizer.zero_grad()\n",
    "    for i in range(len(seq_tensor)-1):\n",
    "        output = rnn(seq_tensor[i])\n",
    "        output = torch.flatten(output)\n",
    "        outputs.append(output)\n",
    "    outputs = torch.stack(outputs)\n",
    "    loss = criterion(outputs, target)\n",
    "    loss.backward()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5523ead1",
   "metadata": {},
   "source": [
    "#### Parameter Initialization, Main Code and Checkpointing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c8c0c754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running.............\n",
      "==> Building model...\n",
      "epoch =  1 Avg Loss =  1.8765507915378672\n",
      "epoch =  2 Avg Loss =  1.2199857945287473\n",
      "epoch =  3 Avg Loss =  1.1066232953099726\n",
      "epoch =  4 Avg Loss =  1.0423968423784307\n",
      "epoch =  5 Avg Loss =  1.0054495394405714\n",
      "epoch =  6 Avg Loss =  0.9677681808626406\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7740\\1407162864.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mperm\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# visit data points in random order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mx_pat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_pats\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# get one input pattern\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0mcur_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_pat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrnn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mcur_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7740\\459866622.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(seq_tensor, rnn)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    486\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m             )\n\u001b[1;32m--> 488\u001b[1;33m         torch.autograd.backward(\n\u001b[0m\u001b[0;32m    489\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nepochs = 100 #number of passes through the entire training set\n",
    "in_size = n_tokens\n",
    "out_size = n_tokens\n",
    "num_layers, HIDDEN_SIZE = 1, 150\n",
    "model_type = 'gru'\n",
    "CHECKPOINT = 'ckpt_mdl_{}_hsize_{}'.format(model_type, HIDDEN_SIZE)\n",
    "\n",
    "losses = []\n",
    "start_epoch = 1\n",
    "RESUME = False\n",
    "print(\"Running.............\")\n",
    "\n",
    "if RESUME:\n",
    "    # Load checkpoint.\n",
    "    print('==> Resuming from checkpoint...')\n",
    "    assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n",
    "    \n",
    "    assert os.path.isdir('epochs'), 'Error: no last epoch tracing directory found!'\n",
    "    \n",
    "    f = open('./epochs/epochtrace.txt', \"r\")\n",
    "    lp = f.read()\n",
    "    \n",
    "    last_epoch = lp.strip()\n",
    "    \n",
    "    checkpoint = torch.load('./checkpoint/' + CHECKPOINT + '.t' + last_epoch)\n",
    "    rnn = checkpoint['mode']\n",
    "    loss = checkpoint['loss']\n",
    "    losses = checkpoint['losses']\n",
    "    start_epoch = checkpoint['epoch']\n",
    "else:\n",
    "    print('==> Building model...')\n",
    "    rnn = MusicGRU(n_tokens, HIDDEN_SIZE, out_size, num_layers)\n",
    "\n",
    "optimizer = torch.optim.AdamW(rnn.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(start_epoch, nepochs + 1):\n",
    "    loss = 0\n",
    "    perm = np.random.permutation(len(training_pats))\n",
    "    for p in perm: # visit data points in random order\n",
    "        x_pat = training_pats[p] # get one input pattern\n",
    "        cur_loss = train(x_pat, rnn)\n",
    "        loss += cur_loss.item()\n",
    "        optimizer.step()\n",
    "    losses.append(loss/len(training_pats))\n",
    "    print(\"epoch = \", epoch, \"Avg Loss = \", loss/len(training_pats))\n",
    "    \n",
    "    state = {\n",
    "            'mode': rnn,\n",
    "            'loss': losses[-1],\n",
    "            'losses': losses,\n",
    "            'epoch': epoch,\n",
    "    }\n",
    "    \n",
    "    last_epoch = str(epoch)\n",
    "    \n",
    "    if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint')\n",
    "    torch.save(state, './checkpoint/' + CHECKPOINT + '.t%s' % epoch)\n",
    "    \n",
    "    if not os.path.isdir('epochs'):\n",
    "            os.mkdir('epochs')\n",
    "    f = open('./epochs/epochtrace.txt', \"w\")\n",
    "    f.write(last_epoch)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987e753a",
   "metadata": {},
   "source": [
    "#### Music Generator and Tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d902c14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_song(prime_str='<start>', max_len=1000, temp=0.8):\n",
    "    with torch.no_grad():\n",
    "        rnn.initHidden()\n",
    "        creation = '<start>'\n",
    "        prime = sentenceToTensor(creation)\n",
    "        for i in range(len(prime)-1):\n",
    "            _ = rnn(prime[i])\n",
    "\n",
    "        # Generate rest of sequence\n",
    "        for j in range(max_len):\n",
    "            out = rnn(sentenceToTensor(creation[-1])).data.view(-1)\n",
    "\n",
    "            out = np.array(np.exp(out/temp))\n",
    "            dist = out / np.sum(out)np\n",
    "\n",
    "            # Add predicted character to string and use as next input        \n",
    "            creation += char_idx[np.random.choice(len(dist), p=dist)]\n",
    "            if creation[-5:] == '<end>':\n",
    "                break\n",
    "        print(creation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c16aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_song(max_len=1000, temp=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d24eb7b",
   "metadata": {},
   "source": [
    "Listen your generated music here: https://abc.rectanglered.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7d38772e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.distributions.categorical import Categorical\n",
    "# def generate(rnn, maxlen=1000):\n",
    "#      # TODO : YOUR CODE GOES HERE\n",
    "#      with torch.no_grad():\n",
    "#          input = torch.tensor(28)\n",
    "#          outputs = []\n",
    "#          outputs.append(index_to_token[input.item()])\n",
    "#          rnn.initHidden()\n",
    "#          for i in range(maxlen):\n",
    "#              output = rnn(input)\n",
    "#              m = Categorical(torch.exp(output))\n",
    "#              input = m.sample()\n",
    "#              word = index_to_token[input.item()]\n",
    "#              outputs.append(word)\n",
    "#          st = \"\"\n",
    "#          for i in range(len(outputs)):\n",
    "#              st = st + outputs[i] + \"\";\n",
    "#          print(st)\n",
    "\n",
    "# for i in range(1):\n",
    "#  generate(rnn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
