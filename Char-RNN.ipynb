{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6277c58e",
   "metadata": {},
   "source": [
    "# MUSIC GENERATION USING RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52828a6e",
   "metadata": {},
   "source": [
    "#### Initialization of helper functions and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb6a0760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start with some packages we need\n",
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a2a47f",
   "metadata": {},
   "source": [
    "#### Sentence Tokenization and indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6419fdbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping unique tokens to integers: {'k': 0, 'v': 1, '4': 2, '=': 3, 'J': 4, '~': 5, 'l': 6, 't': 7, 'e': 8, '0': 9, 'D': 10, '6': 11, 'x': 12, 'Q': 13, '?': 14, '7': 15, 'B': 16, 'M': 17, '8': 18, 'h': 19, 'm': 20, 'L': 21, 'H': 22, ']': 23, '>': 24, '%': 25, 'g': 26, 'A': 27, 'f': 28, 'b': 29, 'c': 30, ' ': 31, 'r': 32, '&': 33, 'W': 34, '2': 35, 'F': 36, 'Y': 37, 'j': 38, '_': 39, '!': 40, 'S': 41, '+': 42, '1': 43, 'o': 44, '\\\\': 45, '-': 46, '9': 47, 'p': 48, 'z': 49, 'n': 50, '(': 51, '/': 52, '5': 53, 'X': 54, 'N': 55, 'q': 56, 'U': 57, 'T': 58, 'y': 59, '3': 60, 's': 61, \"'\": 62, '^': 63, 'a': 64, 'K': 65, 'i': 66, '#': 67, '\\n': 68, 'u': 69, '[': 70, 'E': 71, ',': 72, '|': 73, ':': 74, 'R': 75, 'd': 76, '.': 77, 'G': 78, 'P': 79, '<': 80, 'V': 81, 'w': 82, 'I': 83, '\"': 84, 'C': 85, 'O': 86, ')': 87} \n",
      "\n",
      "example sentence as string: <start>\n",
      "X: 1\n",
      "T:A and D\n",
      "% Nottingham Music Database\n",
      "S:EF\n",
      "Y:AB\n",
      "M:4/4\n",
      "K:A\n",
      "M:6/8\n",
      "P:A\n",
      "f|\"A\"ecc c2f|\"A\"ecc c2f|\"A\"ecc c2f|\"Bm\"BcB \"E7\"B2f|\n",
      "\"A\"ecc c2f|\"A\"ecc c2c/2d/2|\"D\"efe \"E7\"dcB| [1\"A\"Ace a2:|\n",
      " [2\"A\"Ace ag=g||\n",
      "K:D\n",
      "P:B\n",
      "\"D\"f2f Fdd|\"D\"AFA f2e/2f/2|\"G\"g2g ecd|\"Em\"efd \"A7\"cBA|\n",
      "\"D\"f^ef dcd|\"D\"AFA f=ef|\"G\"gfg \"A7\"ABc |[1\"D\"d3 d2e:|[2\"D\"d3 d2||\n",
      "<end>\n",
      " \n",
      "\n",
      "example sentence as tensor: tensor([80, 61,  7, 64, 32,  7, 24, 68, 54, 74, 31, 43, 68, 58, 74, 27, 31, 64,\n",
      "        50, 76, 31, 10, 68, 25, 31, 55, 44,  7,  7, 66, 50, 26, 19, 64, 20, 31,\n",
      "        17, 69, 61, 66, 30, 31, 10, 64,  7, 64, 29, 64, 61,  8, 68, 41, 74, 71,\n",
      "        36, 68, 37, 74, 27, 16, 68, 17, 74,  2, 52,  2, 68, 65, 74, 27, 68, 17,\n",
      "        74, 11, 52, 18, 68, 79, 74, 27, 68, 28, 73, 84, 27, 84,  8, 30, 30, 31,\n",
      "        30, 35, 28, 73, 84, 27, 84,  8, 30, 30, 31, 30, 35, 28, 73, 84, 27, 84,\n",
      "         8, 30, 30, 31, 30, 35, 28, 73, 84, 16, 20, 84, 16, 30, 16, 31, 84, 71,\n",
      "        15, 84, 16, 35, 28, 73, 68, 84, 27, 84,  8, 30, 30, 31, 30, 35, 28, 73,\n",
      "        84, 27, 84,  8, 30, 30, 31, 30, 35, 30, 52, 35, 76, 52, 35, 73, 84, 10,\n",
      "        84,  8, 28,  8, 31, 84, 71, 15, 84, 76, 30, 16, 73, 31, 70, 43, 84, 27,\n",
      "        84, 27, 30,  8, 31, 64, 35, 74, 73, 68, 31, 70, 35, 84, 27, 84, 27, 30,\n",
      "         8, 31, 64, 26,  3, 26, 73, 73, 68, 65, 74, 10, 68, 79, 74, 16, 68, 84,\n",
      "        10, 84, 28, 35, 28, 31, 36, 76, 76, 73, 84, 10, 84, 27, 36, 27, 31, 28,\n",
      "        35,  8, 52, 35, 28, 52, 35, 73, 84, 78, 84, 26, 35, 26, 31,  8, 30, 76,\n",
      "        73, 84, 71, 20, 84,  8, 28, 76, 31, 84, 27, 15, 84, 30, 16, 27, 73, 68,\n",
      "        84, 10, 84, 28, 63,  8, 28, 31, 76, 30, 76, 73, 84, 10, 84, 27, 36, 27,\n",
      "        31, 28,  3,  8, 28, 73, 84, 78, 84, 26, 28, 26, 31, 84, 27, 15, 84, 27,\n",
      "        16, 30, 31, 73, 70, 43, 84, 10, 84, 76, 60, 31, 76, 35,  8, 74, 73, 70,\n",
      "        35, 84, 10, 84, 76, 60, 31, 76, 35, 73, 73, 68, 80,  8, 50, 76, 24, 68]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def sentenceToTensor(tokens):\n",
    "    # Convert list of strings to tensor of token indices (integers)\n",
    "    #\n",
    "    # Input\n",
    "    #  tokens_list : list of strings, e.g. ['<SOS>','lion','eat','man','<EOS>']\n",
    "    # Output\n",
    "    #  1D tensor of the same length (integers), e.g., tensor([ 2, 18, 13, 19,  0])\n",
    "    out = torch.zeros(len(tokens)).long()\n",
    "    for i, token in enumerate(tokens):\n",
    "        out[i] = char_idx.index(token)\n",
    "    return out\n",
    "\n",
    "# load and process the set of simple sentences\n",
    "with open('data/input.txt','r') as fid:\n",
    "    lines = fid.readlines()\n",
    "\n",
    "cur_line = ''\n",
    "input_lines = []\n",
    "for line in lines:\n",
    "    if line == '\\n':\n",
    "        input_lines.append(cur_line)\n",
    "        cur_line = ''\n",
    "        continue\n",
    "    cur_line += line\n",
    "\n",
    "input_lines = [s for s in input_lines if len(s)>0]\n",
    "input_lines = ['<start>\\n'+s+'<end>\\n' for s in input_lines]\n",
    "\n",
    "char_idx = ''.join(set(list((open('data/input.txt','r').read()) + '<start>' + '<end>')))\n",
    "unique_tokens = list(char_idx)\n",
    "    \n",
    "n_tokens = len(unique_tokens) # all words and special tokens\n",
    "\n",
    "token_to_index = {t : i for i,t in enumerate(unique_tokens)}\n",
    "index_to_token = {i : t for i,t in enumerate(unique_tokens)}\n",
    "\n",
    "training_pats = [sentenceToTensor(s) for s in input_lines]\n",
    "training_pats = [s for s in training_pats if s.size()[0]>0]\n",
    "\n",
    "ntrain = len(training_pats)\n",
    "print('mapping unique tokens to integers: %s \\n' % token_to_index)\n",
    "print('example sentence as string: %s \\n' % ''.join(input_lines[0]))\n",
    "print('example sentence as tensor: %s \\n' % training_pats[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaad770c",
   "metadata": {},
   "source": [
    "### Music Recurrent Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31ce100",
   "metadata": {},
   "source": [
    "#### RNN Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fe40b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicGRU(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "        self.word_embeddings = nn.Embedding(input_size, hidden_size)\n",
    "        self.rnn = nn.GRU(hidden_size, hidden_size, num_layers)\n",
    "        self.fc1 = nn.Linear(self.hidden_size, self.output_size)\n",
    "        \n",
    "    def forward(self, input_token):\n",
    "        input_embed = self.word_embeddings(input_token)\n",
    "        input_embed = input_embed.view(1, 1, -1)\n",
    "        rnn_out, self.hidden = self.rnn(input_embed, self.hidden)\n",
    "        output = self.fc1(rnn_out.view(1, -1))\n",
    "        return output\n",
    "\n",
    "    def initHidden(self):\n",
    "        # Returns length hidden_size 1D tensor of zeros\n",
    "        self.hidden = torch.zeros(self.num_layers, 1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9571eaa4",
   "metadata": {},
   "source": [
    "#### Training Loop and Loss Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8b6b7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(seq_tensor, rnn):\n",
    "    target = seq_tensor\n",
    "    target = torch.cat([target[1:]])\n",
    "    outputs = []\n",
    "    rnn.initHidden()\n",
    "    optimizer.zero_grad()\n",
    "    for i in range(len(seq_tensor)-1):\n",
    "        output = rnn(seq_tensor[i])\n",
    "        output = torch.flatten(output)\n",
    "        outputs.append(output)\n",
    "    outputs = torch.stack(outputs)\n",
    "    loss = criterion(outputs, target)\n",
    "    loss.backward()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5523ead1",
   "metadata": {},
   "source": [
    "#### Parameter Initialization, Main Code and Checkpointing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c0c754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running.............\n",
      "==> Building model...\n"
     ]
    }
   ],
   "source": [
    "nepochs = 100 #number of passes through the entire training set\n",
    "in_size = n_tokens\n",
    "out_size = n_tokens\n",
    "num_layers, HIDDEN_SIZE = 1, 150\n",
    "model_type = 'gru'\n",
    "CHECKPOINT = 'ckpt_mdl_{}_hsize_{}'.format(model_type, HIDDEN_SIZE)\n",
    "\n",
    "losses = []\n",
    "start_epoch = 1\n",
    "RESUME = False\n",
    "print(\"Running.............\")\n",
    "\n",
    "if RESUME:\n",
    "    # Load checkpoint.\n",
    "    print('==> Resuming from checkpoint...')\n",
    "    assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n",
    "    \n",
    "    assert os.path.isdir('epochs'), 'Error: no last epoch tracing directory found!'\n",
    "    \n",
    "    f = open('./epochs/epochtrace.txt', \"r\")\n",
    "    lp = f.read()\n",
    "    \n",
    "    last_epoch = lp.strip()\n",
    "    \n",
    "    checkpoint = torch.load('./checkpoint/' + CHECKPOINT + '.t' + last_epoch)\n",
    "    rnn = checkpoint['mode']\n",
    "    loss = checkpoint['loss']\n",
    "    losses = checkpoint['losses']\n",
    "    start_epoch = checkpoint['epoch']\n",
    "else:\n",
    "    print('==> Building model...')\n",
    "    rnn = MusicGRU(n_tokens, HIDDEN_SIZE, out_size, num_layers)\n",
    "\n",
    "optimizer = torch.optim.AdamW(rnn.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(start_epoch, nepochs + 1):\n",
    "    loss = 0\n",
    "    perm = np.random.permutation(len(training_pats))\n",
    "    for p in perm: # visit data points in random order\n",
    "        x_pat = training_pats[p] # get one input pattern\n",
    "        cur_loss = train(x_pat, rnn)\n",
    "        loss += cur_loss.item()\n",
    "        optimizer.step()\n",
    "    losses.append(loss/len(training_pats))\n",
    "    print(\"epoch = \", epoch, \"Avg Loss = \", loss/len(training_pats))\n",
    "    \n",
    "    state = {\n",
    "            'mode': rnn,\n",
    "            'loss': losses[-1],\n",
    "            'losses': losses,\n",
    "            'epoch': epoch,\n",
    "    }\n",
    "    \n",
    "    last_epoch = str(epoch)\n",
    "    \n",
    "    if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint')\n",
    "    torch.save(state, './checkpoint/' + CHECKPOINT + '.t%s' % epoch)\n",
    "    \n",
    "    if not os.path.isdir('epochs'):\n",
    "            os.mkdir('epochs')\n",
    "    f = open('./epochs/epochtrace.txt', \"w\")\n",
    "    f.write(last_epoch)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987e753a",
   "metadata": {},
   "source": [
    "#### Music Generator and Tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d902c14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_song(prime_str='<start>', max_len=1000, temp=0.8):\n",
    "    with torch.no_grad():\n",
    "        rnn.initHidden()\n",
    "        creation = '<start>'\n",
    "        prime = sentenceToTensor(creation)\n",
    "        for i in range(len(prime)-1):\n",
    "            _ = rnn(prime[i])\n",
    "\n",
    "        # Generate rest of sequence\n",
    "        for j in range(max_len):\n",
    "            out = rnn(sentenceToTensor(creation[-1])).data.view(-1)\n",
    "\n",
    "            out = np.array(np.exp(out/temp))\n",
    "            dist = out / np.sum(out)np\n",
    "\n",
    "            # Add predicted character to string and use as next input        \n",
    "            creation += char_idx[np.random.choice(len(dist), p=dist)]\n",
    "            if creation[-5:] == '<end>':\n",
    "                break\n",
    "        print(creation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c16aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_song(max_len=1000, temp=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d24eb7b",
   "metadata": {},
   "source": [
    "Listen your generated music here: https://abc.rectanglered.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7d38772e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.distributions.categorical import Categorical\n",
    "# def generate(rnn, maxlen=1000):\n",
    "#      # TODO : YOUR CODE GOES HERE\n",
    "#      with torch.no_grad():\n",
    "#          input = torch.tensor(28)\n",
    "#          outputs = []\n",
    "#          outputs.append(index_to_token[input.item()])\n",
    "#          rnn.initHidden()\n",
    "#          for i in range(maxlen):\n",
    "#              output = rnn(input)\n",
    "#              m = Categorical(torch.exp(output))\n",
    "#              input = m.sample()\n",
    "#              word = index_to_token[input.item()]\n",
    "#              outputs.append(word)\n",
    "#          st = \"\"\n",
    "#          for i in range(len(outputs)):\n",
    "#              st = st + outputs[i] + \"\";\n",
    "#          print(st)\n",
    "\n",
    "# for i in range(1):\n",
    "#  generate(rnn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
